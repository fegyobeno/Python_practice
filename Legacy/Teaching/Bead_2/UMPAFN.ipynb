{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Időjárás-előrejelzési adatkészlet vizsgálata\n",
        "\n",
        "A több, mint 2500 időjárás-megfigyelést tartalmazó adathalmaz feldolgozásával csapadék előfordulására szeretnénk előrejelzést adni  különböző időjárási körülmények alapján. A gépi tanulás osztályozási technikáit használjuk az elemzéshez. A scikit-learn Python könyvtárból a logisztikus regresszió, a döntési fák és számos más algoritmus alkalmazásával valamint különböző adatvizualizálási eszközökkel dolgozunk.\n",
        "\n",
        "Nincs információnk arról, hogy milyen dátum és időpontokban mérték a jellemzőket, de azt tudjuk, hogy az adatok időrendi sorrendben vannak. Néhány esetben az adatok hiányosak vagy tévedésből többszörösen rögzítettek lehetnek. Az első oszlopban az adott mérés sorszáma szerepel (Id). Az adatállomány a következő időjárási jellemzők mért értékeit tartalmazza:\n",
        "\n",
        "Temperature: hőmérséklet (Celsius fok)\n",
        "\n",
        "Humidity: a levegő páratartalma (%-ban megadva)\n",
        "\n",
        "Wind_Speed: a szél erőssége (km/h)\n",
        "\n",
        "Cloud_Cover: az égbolt felhővel való fedettsége (%-ban megadva)  \n",
        "\n",
        "Pressure: a légnyomás értéke (hPa)\n",
        "\n",
        "Rain: 'rain', ha esik az eső ill. 'no rain', ha nem esik az eső.\n"
      ],
      "metadata": {
        "id": "_Xq3cWXQbnC0"
      },
      "id": "_Xq3cWXQbnC0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A megoldandó feladat leírása:\n",
        "\n",
        "A #-tel kezdődő és ?-eket tartalmazó kódban a ? helyére mindig be kell írni a hiányzó kódrészletet, amivel a feladatban kért eredményt el lehet érni. Ezután aktívvá kell tenni a kódsort és végre kell hajtani.\n",
        "\n"
      ],
      "metadata": {
        "id": "750eD0h2dNG3"
      },
      "id": "750eD0h2dNG3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importálás\n",
        "\n",
        "Első lépésként importáljuk a Numpy, Pandas, Seaborn és Matplotlib.pyplot könyvtárakat az adatbeolvasáshoz, adatelőkészítéshez és adatvizualizációhoz. Használjuk a szokásos rövidítéseket alias name-ként az egyes könyvtárakhoz (np, pd, sns és plt)."
      ],
      "metadata": {
        "id": "vw4OvTPmdmSa"
      },
      "id": "vw4OvTPmdmSa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73add4be",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-11-11T05:37:20.886890Z",
          "iopub.status.busy": "2024-11-11T05:37:20.886476Z",
          "iopub.status.idle": "2024-11-11T05:37:23.566791Z",
          "shell.execute_reply": "2024-11-11T05:37:23.564575Z"
        },
        "papermill": {
          "duration": 2.692575,
          "end_time": "2024-11-11T05:37:23.569981",
          "exception": false,
          "start_time": "2024-11-11T05:37:20.877406",
          "status": "completed"
        },
        "tags": [],
        "id": "73add4be"
      },
      "outputs": [],
      "source": [
        "# A szükséges könyvtárak importálása\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adatok betöltése és betekintés a DataFrame-be\n",
        "\n",
        "Töltsük be a weather_forecast_data nevű CSV adatfájlunk tartalmát egy df nevű DataFrame-be, és jelenítsük meg a df első 5 és utolsó 5 darab sorát.\n",
        "\n",
        "Ezek után meg kell vizsgálnunk, hogy szükséges-e adattisztítási lépéseket elvégeznünk."
      ],
      "metadata": {
        "id": "0SVCxkrBbWhB"
      },
      "id": "0SVCxkrBbWhB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5fd5e8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-11T05:37:23.585816Z",
          "iopub.status.busy": "2024-11-11T05:37:23.585366Z",
          "iopub.status.idle": "2024-11-11T05:37:23.596801Z",
          "shell.execute_reply": "2024-11-11T05:37:23.595601Z"
        },
        "papermill": {
          "duration": 0.022233,
          "end_time": "2024-11-11T05:37:23.598968",
          "exception": false,
          "start_time": "2024-11-11T05:37:23.576735",
          "status": "completed"
        },
        "tags": [],
        "id": "2a5fd5e8"
      },
      "outputs": [],
      "source": [
        "# Adatok beolvasása és megjelenítése\n",
        "df = pd.read_csv('./content/weather_forecast_data.csv')\n",
        "display(df.head())\n",
        "display(df.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Írassuk ki, hogy hány adatsorunk van a dataFrame-ben.\n"
      ],
      "metadata": {
        "id": "0s4L23Cq_4EH"
      },
      "id": "0s4L23Cq_4EH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Adatsorok száma\n",
        "print(len(df))"
      ],
      "metadata": {
        "id": "jgtRrN9O_3BX"
      },
      "id": "jgtRrN9O_3BX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Írassuk ki azt az információt, amely megadja azt, hogy az oszlopokban milyen típusú értékek szerepelnek, valamint megmutatja az oszlopokban szereplő NaN értékek számát is."
      ],
      "metadata": {
        "id": "wcwxTu8iCpJp"
      },
      "id": "wcwxTu8iCpJp"
    },
    {
      "cell_type": "code",
      "source": [
        "# Informácó a DataFrame adatairól\n",
        "df.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OmmxwmWQDPQJ"
      },
      "id": "OmmxwmWQDPQJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellenőrizzük az isnull().sum() metódussal, hogy melyik oszlopban hány darab NaN érték található."
      ],
      "metadata": {
        "id": "sQdl7xjf_jD3"
      },
      "id": "sQdl7xjf_jD3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Oszloponként a NaN értékek darabszáma\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bTnNiCbG_yGD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "696e5bd8-c247-4758-bc93-6a65a5f69154"
      },
      "id": "bTnNiCbG_yGD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f55c5a232da8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Oszloponként a NaN értékek darabszáma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adattisztítás\n",
        "Töröljük ki a kizárólag NaN-t tartalmazó DataFrame 'Extra_column' nevű oszlopát, valamint törüljük ki az 'Id' nevű oszlopot is."
      ],
      "metadata": {
        "id": "bwcIK7Jv-y2g"
      },
      "id": "bwcIK7Jv-y2g"
    },
    {
      "cell_type": "code",
      "source": [
        "# A fölösleges oszlopok eltávolítása\n",
        "df = df.drop('Extra_column', axis=1)\n",
        "df = df.drop('Id', axis=1)"
      ],
      "metadata": {
        "id": "mmKNVc0kAcz2"
      },
      "id": "mmKNVc0kAcz2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellenőrizzük, hogy sikeres volt-e a törlés."
      ],
      "metadata": {
        "id": "EHEzn9P07tdo"
      },
      "id": "EHEzn9P07tdo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce86c89",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-11T05:37:23.642032Z",
          "iopub.status.busy": "2024-11-11T05:37:23.641631Z",
          "iopub.status.idle": "2024-11-11T05:37:23.648991Z",
          "shell.execute_reply": "2024-11-11T05:37:23.647788Z"
        },
        "papermill": {
          "duration": 0.017047,
          "end_time": "2024-11-11T05:37:23.650997",
          "exception": false,
          "start_time": "2024-11-11T05:37:23.633950",
          "status": "completed"
        },
        "tags": [],
        "id": "1ce86c89",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Ellenőrzés\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Írjuk ki, hogy ezek után összesen hány helyen van hiányzó adat a DataFrame-ben."
      ],
      "metadata": {
        "id": "jfqBOL75AwPh"
      },
      "id": "jfqBOL75AwPh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Összesen hány darab NaN érték van\n",
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "AHSZ6Uz0A9mC"
      },
      "id": "AHSZ6Uz0A9mC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mivel számottevően nem fog módosulni az adatmennyiség, ezért töröljük ki a NaN értékeket tartalmazó sorokat.\n",
        "\n",
        "Töröljük ki a duplikált sorokat is (ha vannak ilyenek).\n",
        "\n",
        "Írassuk ki az adattisztítási lépések után, hogy hány sor található a DataFrame-ben."
      ],
      "metadata": {
        "id": "9Q0cSL_SBKdc"
      },
      "id": "9Q0cSL_SBKdc"
    },
    {
      "cell_type": "code",
      "source": [
        "# A NaN értékeket tartalmazó sorok és a duplikált sorok törlése\n",
        "df = df.dropna()\n",
        "df = df.drop_duplicates()\n",
        "print(len(df))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O4cEJWD3BRrF"
      },
      "id": "O4cEJWD3BRrF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adatok megjelenítése különböző szempontok szerint - Adatvizualizáció\n",
        "\n",
        "Alkalmazzuk a Seaborn könyvtár különböző diagramkészítő metódusait hisztogramok, boxplot-ok, vonal- és scatter diagramok valamint egyéb megjelenítési lehetőségek bemutatására.\n",
        "\n",
        "Először jelenítsük meg a Seaborn könyvtár countplot() metódusával az esős ill. a nem esős napok számát. A megadott kódban szereplő ?-ek helyére írjuk be a hiányzó kódrészletet."
      ],
      "metadata": {
        "id": "9h21YuijalIw"
      },
      "id": "9h21YuijalIw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Az esős ill. a nem esős napok számának megjelenítése\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Rain', data=df, hue='Rain', palette=['blue','gold'])\n",
        "plt.title('Count of Rainy vs Non-Rainy Days')\n",
        "plt.xlabel('Rain')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yaGqzbvSosF4",
        "collapsed": true
      },
      "id": "yaGqzbvSosF4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Következő lépésként vizsgáljuk meg a felhővel borítottságot a 'Cloud_Cover' oszlop adatai alapján. Ehhez illesszünk egy új oszlopot a DataFrame-hez 'Outlook' névvel. Ebben jelenjen meg a 'sunny' kifejezés, ha a felhővel fedettség 15%-nál kisebb, a 'very cloudy' érték ha 70%-nál nagyobb és az 'overcast' az egyéb esetekben."
      ],
      "metadata": {
        "id": "8D-IYQDRO4de"
      },
      "id": "8D-IYQDRO4de"
    },
    {
      "cell_type": "code",
      "source": [
        "# Az Outlook oszlop generálása\n",
        "df['Outlook'] = pd.cut(df['Cloud_Cover'], bins=[0, 15, 70, 100], labels=['sunny', 'overcast', 'very cloudy'])\n",
        "df"
      ],
      "metadata": {
        "id": "HjpY3CQbRe8P"
      },
      "id": "HjpY3CQbRe8P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A felhővel borítottság megjelenítésére használjuk a Seaborn könyvtár countplot() metódusát az Outlook oszlop elemeire. A színpalettát állítsuk be a gold (sunny), darkgrey (very cloudy) és skyblue (overcast) értékekre."
      ],
      "metadata": {
        "id": "oasRyB7ERsty"
      },
      "id": "oasRyB7ERsty"
    },
    {
      "cell_type": "code",
      "source": [
        "# Az Outlook oszlop kategóriáinak megjelenítése\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Outlook', data=df, palette=['gold', 'skyblue', 'darkgrey'])\n",
        "plt.title('Count Overcast, Sunny and Very Cloudy Days')\n",
        "plt.xlabel('Outlook')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(axis='y')\n",
        "\n"
      ],
      "metadata": {
        "id": "A3gfgiCMSl4Y"
      },
      "id": "A3gfgiCMSl4Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Az adatok eloszlásának megjelenítése\n",
        "\n",
        "Jelenítsük meg 2 soros és 3 oszlopos többszörös diagramként (subplot) a hőmérséklet, páratartalom, szélsebesség, felhővel borítottság és a légnyomás értékek gyakoriságát a Seaborn histplot() metódusával, amellyel a KDE adatsűrűségi görbét is kirajzoljuk. Az adattartományt minden esetben 30 sávra osszuk fel.\n",
        "A megadott kódban a ?-ek helyére írjuk be amegfelelő értékeket."
      ],
      "metadata": {
        "id": "xx5d3vc0c-pv"
      },
      "id": "xx5d3vc0c-pv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8202f997",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-11T05:37:23.791077Z",
          "iopub.status.busy": "2024-11-11T05:37:23.790678Z",
          "iopub.status.idle": "2024-11-11T05:37:23.814746Z",
          "shell.execute_reply": "2024-11-11T05:37:23.813551Z"
        },
        "papermill": {
          "duration": 0.035072,
          "end_time": "2024-11-11T05:37:23.817174",
          "exception": false,
          "start_time": "2024-11-11T05:37:23.782102",
          "status": "completed"
        },
        "tags": [],
        "id": "8202f997",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Hisztogramok megjelenítése a Temperature, Humidity, Wind Speed, Cloud Cover és Pressure oszlopokra KDE-vel\n",
        "plt.figure(figsize=(15, 10))\n",
        "features = ['Temperature', 'Humidity', 'Wind_Speed', 'Cloud_Cover', 'Pressure']\n",
        "\n",
        "for i, feature in enumerate(features, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.histplot(df[feature], kde=True, bins=30, color='teal')\n",
        "    plt.title(f'Histogram of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statisztika készítése és megjelenítése\n",
        "Határozzuk meg a DataFrame numerikus oszlopainak statisztikai jellemzőit a describe() metódussal."
      ],
      "metadata": {
        "id": "hQk3XUiKf2FI"
      },
      "id": "hQk3XUiKf2FI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Statisztikai táblázat a numerikus adatokra\n",
        "df.describe()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5SX-308VgSl2"
      },
      "id": "5SX-308VgSl2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jelenítsük meg egy 3 soros és 2 oszlopos elrendezésű subplot-ban a numerikus oszlopok terjedelmét, mediánját és kvartiliseit a Seaborn boxplot diagramjával.\n",
        "\n",
        "A boxplot-okat minden esetben a Rain oszlop értékei szerinti csoportosításban, skyblue és tomato színekkel ábrázoljuk.\n",
        "Írjuk be a ?-ek helyére a hiányzó kulcssszavakat és paramétereket."
      ],
      "metadata": {
        "id": "bpiaw2stgkRM"
      },
      "id": "bpiaw2stgkRM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot-ok megjelenítése a Temperature, Humidity, Wind Speed, Cloud Cover és Pressure oszlopokra Rain szerinti csoportosítással\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, column in enumerate(df.columns[:-2]):\n",
        "    plt.subplot(3, 2, i + 1)\n",
        "    sns.boxplot(x='Rain', y=column, data=df, hue='Rain', palette=['skyblue','tomato'])\n",
        "    plt.title(f'{column} vs Rain')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m6h3lU1kkkKV",
        "collapsed": true
      },
      "id": "m6h3lU1kkkKV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Az adatok közötti kapcsolatok megjelenítése\n",
        "Ebben a részben további adatmegjelenítési lehetőségeket mutatunk be. Scatter diagram és vonaldiagram bemutatásával tesszük szemléletessé az adatainkat.\n",
        "\n",
        "Első lépésként jelenítsük meg a DataFrame numerikus értékeit a Seaborn pairplot() metódusával coolwarm színpalettával a Rain oszlop értékei szerinti csoportosításban.\n",
        "A ?-ek helyére írjuk be a hiányzó kódrészleteket."
      ],
      "metadata": {
        "id": "Yyu2QSG_m42t"
      },
      "id": "Yyu2QSG_m42t"
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot diagram ábrázolása a Rain oszlop szerinti csoportosítással\n",
        "sns.pairplot(df, hue='Rain', palette='coolwarm')\n",
        "plt.suptitle('Pair Plot of Weather Data', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "za5-xZLRfuNy",
        "collapsed": true
      },
      "id": "za5-xZLRfuNy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Következő lépésként rajzoljunk overlay vonaldiagramot a hőmérséklet és a páratartalom mérésenkénti értékeinek bemutatásásra. Használjuk a Matplotlib könyvtár plot metódusát a két grafikon közös diagramban történő ábrázolásához. A Humidity oszlop értékeinek megjelenítéséhez a 'skyblue' szín használjuk és írjuk be a hiányzó kódrészleteket a ?-ek helyére."
      ],
      "metadata": {
        "id": "gUpcnn0yslKA"
      },
      "id": "gUpcnn0yslKA"
    },
    {
      "cell_type": "code",
      "source": [
        "# Vonaldiagram: a Temperature és a Humidity megjelenítése az Index oszlop szerinti sorrendben\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Temperature line plot\n",
        "plt.plot(df['Temperature'], label='Temperature', color='lightgreen')\n",
        "plt.plot(df['Humidity'], label='Humidity', color='skyblue')\n",
        "\n",
        "plt.title('Temperature and Humidity Over Time')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qifsGp_bqDV9",
        "collapsed": true
      },
      "id": "qifsGp_bqDV9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jelenítsük meg a hőmérséklet és a páratartalom közti kapcsolatot a Seaborn scatterplot() és kdeplot() metódusaival a Rain oszlop értékei szerinti bontásban.\n",
        "helyezzük el egy 1 sor 2 oszlopos subplot-ban a két diagramot.\n",
        "\n",
        "A ?-ek helyére írjuk be a hiányzó kódrészleteket."
      ],
      "metadata": {
        "id": "-JWVX4vo8T7p"
      },
      "id": "-JWVX4vo8T7p"
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter diagram és  KDE diagram a  Temperature és a Humidity értékek kapcsolatára\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Temperature and Humidity')\n",
        "sns.scatterplot(x=df['Temperature'],y=df['Humidity'],hue=df['Rain'])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('Temperature and Humidity')\n",
        "sns.kdeplot(x=df['Temperature'],y=df['Humidity'],hue=df['Rain'])"
      ],
      "metadata": {
        "id": "jBI2cg5-Kur8"
      },
      "id": "jBI2cg5-Kur8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A DataFrame mentése CSV fájlba\n",
        "\n",
        "Mentsük el a vizsgált df DataFrame-et a cleaned_weather_data.csv fájlba a Pandas to_csv() metódusával, az Index oszlop mellőzésével."
      ],
      "metadata": {
        "id": "oPigWtaM2P0Y"
      },
      "id": "oPigWtaM2P0Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# df mentése CSV fájlba\n",
        "df.to_csv('cleaned_weater_data.csv', index=False)"
      ],
      "metadata": {
        "id": "fCzzPfVF3Tnk"
      },
      "id": "fCzzPfVF3Tnk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Korreláció vizsgálata\n",
        "A korreláció vizsgálatához készítsünk egy df_new új DataFrame-et a cleaned_weather_data.csv adatainak beolvasásával.\n",
        "\n",
        "A df_new DataFrame-et egészítsük ki egy új Rain_code nevű oszloppal, amelybe írjuk be az 1 értéket ha esett az eső, ill. a 0 értéket, ha nem esett az eső.\n",
        "\n",
        "Írjuk be a ?-ek helyére a hiányzó kódrészleteket. Jelenítsük meg a new_df első 10 adatsorát.\n",
        "\n"
      ],
      "metadata": {
        "id": "-7PtYy7LenHa"
      },
      "id": "-7PtYy7LenHa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Adatok beolvasása és a Rain_code oszlop feltöltése\n",
        "df_new = pd.read_csv('cleaned_weather_data.csv')\n",
        "\n",
        "df_new['Rain_code'] = df_new['Rain'].map({'rain': 1, 'no rain': 0})\n",
        "display(df_new.head(10))"
      ],
      "metadata": {
        "id": "S2HdGfe1ur3V"
      },
      "id": "S2HdGfe1ur3V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A df_new DataFrame-ben töröljük ki a Rain és az Outlook oszlopokat."
      ],
      "metadata": {
        "id": "edtGU51GgfV_"
      },
      "id": "edtGU51GgfV_"
    },
    {
      "cell_type": "code",
      "source": [
        "del df_new['Rain']\n",
        "del df_new['Outlook']\n",
        "df_new.head()"
      ],
      "metadata": {
        "id": "ovaD1Td9abd4"
      },
      "id": "ovaD1Td9abd4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hozzuk létre a df_new korrelációs mátrixát egy heatmap diagrammal együtt."
      ],
      "metadata": {
        "id": "cdobX6ApgYvH"
      },
      "id": "cdobX6ApgYvH"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 5))\n",
        "sns.heatmap(df_new.corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x9dvCQFbs_VT"
      },
      "id": "x9dvCQFbs_VT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modellépítés\n",
        "Elemezzük az adatainkat különböző gépi tanulási algoritmusokkal, hogy előrejelzéseket tudjunk adni a csapadék előfordulására, és hogy feltárjunk esetleges rejtett összefüggéseket az adatok között.\n",
        "Különböző Sklearn modelleket választunk, ezeket betanítjuk, majd bemutatjuk a pontosságukat. Az eredményeket különböző típusú diagramokon jelenítjük meg."
      ],
      "metadata": {
        "id": "9rG4Pnv6Tn6r"
      },
      "id": "9rG4Pnv6Tn6r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A modellépítés lépései:\n",
        "Importáljuk a szükséges modulokat.\n",
        "A weather_data nevű új DataFrame-be betöltjük a cleaned_weather_data.csv fájl adatait.\n",
        "Először kitöröljük az Outlook oszlopot, amit az elemzésben nem kívánunk felhasználni. Következő lépésben konvertáljuk a szöveges adatokat tartalmazó Rain oszlopot numerikussá. Megadjuk a bemeneti halmazt (X), ezek a mért időjárási tényezők és a célértékeket (y) is, ezek a Rain oszlop értékei.\n",
        "\n",
        "Ezután következik a weather_data DataFrame adatainak felosztása tanító és teszt (train - test) halmazokra 70% és 30% arányban. A bemeneti X_train és X_test halmazokból a StandardScaler modul alkalmazásával skálázott adathalmazokat is készítünk.\n",
        "\n"
      ],
      "metadata": {
        "id": "uLyNr2NoXEoE"
      },
      "id": "uLyNr2NoXEoE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5001ba3b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-11T05:37:23.833769Z",
          "iopub.status.busy": "2024-11-11T05:37:23.833382Z",
          "iopub.status.idle": "2024-11-11T05:37:24.285731Z",
          "shell.execute_reply": "2024-11-11T05:37:24.284387Z"
        },
        "papermill": {
          "duration": 0.46349,
          "end_time": "2024-11-11T05:37:24.288132",
          "exception": false,
          "start_time": "2024-11-11T05:37:23.824642",
          "status": "completed"
        },
        "tags": [],
        "id": "5001ba3b"
      },
      "outputs": [],
      "source": [
        "# Importálás, adatbetöltés, típuskonvertálás, adatfelosztások, adatskálázás\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Adatok betöltése\n",
        "weather_data = pd.read_csv('./content/cleaned_weather_data.csv')\n",
        "del weather_data['Outlook']\n",
        "\n",
        "\n",
        "# A Rain oszlop adatainak numerikussá alakítása\n",
        "le = LabelEncoder()\n",
        "weather_data['Rain'] = le.fit_transform(weather_data['Rain'])\n",
        "\n",
        "\n",
        "# Adatfelosztás jellemzők (X = features) és célértékek (y = target) szerint\n",
        "X = weather_data.drop('Rain', axis=1)\n",
        "y = weather_data['Rain']\n",
        "\n",
        "# Az adatok felosztása tanító és teszt halmazra\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Skálázzuk a bemeneti jellemzőket\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A modell alkalmazása\n",
        "\n",
        "A kiválasztott  ML modellre következik a modell betanítása, az eredmények kiírása, a modell értékelése és az eredmények megjelenítése.\n",
        "\n",
        "A modellek értékeléséhez megadjuk a pontosságot (accuracy), a konfúziós mátrixot, és megjelenítjük a további metrikák szerinti értékelést is (precision, recall,f1-score,support) a classification_report() metódussal.\n",
        "\n",
        "A megjelenítéshez mindig az adott modellre jellemző diagramtípus kerül kiválasztásra."
      ],
      "metadata": {
        "id": "TLXP2tYTIJFP"
      },
      "id": "TLXP2tYTIJFP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. modell: Logistic Regression\n",
        "\n",
        "Ezt a modellt a skálázott bemeneti adatokra alkalmazzuk. A tanítást a fit() metódussal végezzük el a bemeneti train halmazra, és a predict() metódussal adunk előrejelzést a kívánt célértékekre.\n",
        "\n"
      ],
      "metadata": {
        "id": "_NV42oUIbJ7U"
      },
      "id": "_NV42oUIbJ7U"
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "log_reg_pred = log_reg.predict(X_test_scaled)\n",
        "\n",
        "# Logistic Regression értékelése\n",
        "print(\"Logistic Regression Metrics:\")\n",
        "print(f\"  Accuracy: {accuracy_score(y_test, log_reg_pred):.2f}\")\n",
        "print(f\"  Confusion Matrix:\\n {confusion_matrix(y_test, log_reg_pred)}\")\n",
        "print(classification_report(y_test , log_reg.predict(X_test_scaled)))"
      ],
      "metadata": {
        "id": "3FAjPSmoa3q-"
      },
      "id": "3FAjPSmoa3q-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A megjelenítést a ROC görbe megrajzolásával végezzük el."
      ],
      "metadata": {
        "id": "thBPC1n5LOFI"
      },
      "id": "thBPC1n5LOFI"
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ROC görbe megjelenítése\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from matplotlib.colors import ListedColormap\n",
        "log_reg_probs = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, log_reg_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Logistic Regression ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lnukASQMF5nD"
      },
      "id": "lnukASQMF5nD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. modell: Support Vector Classifier (SVC)\n",
        "\n",
        "Ebben az esetben is a skálázott bemeneti adatokkal dolgozunk. A ?-ek helyére írjuk be a hiányzó kódrészleteket."
      ],
      "metadata": {
        "id": "TL9MfCG8ZYQJ"
      },
      "id": "TL9MfCG8ZYQJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Classifier (SVC) Model\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_clf = SVC(random_state=42)\n",
        "svc_clf.fit(X_train_scaled, y_train)\n",
        "svc_clf_pred = svc_clf.predict(X_test_scaled)\n",
        "\n",
        "# SVC értékelése\n",
        "print(\"Support Vector Classifier Metrics:\")\n",
        "print(f\"  Accuracy: {accuracy_score(y_test, svc_clf_pred):.2f}\")\n",
        "print(f\"  Confusion Matrix:\\n {confusion_matrix(y_test, svc_clf_pred)}\")\n",
        "print(classification_report(y_test , svc_clf.predict(X_test_scaled)))"
      ],
      "metadata": {
        "id": "TemC_LVWwpFl"
      },
      "id": "TemC_LVWwpFl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix megjelenítése\n",
        "cm = confusion_matrix(y_test, svc_clf_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=['No Rain', 'Rain'], yticklabels=['No Rain', 'Rain'])\n",
        "plt.title(\"SVC Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"Actual Class\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CERpktY1EhzF"
      },
      "id": "CERpktY1EhzF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. modell:  K-Nearest Neighbors\n",
        "\n",
        "Ebben az esetben is a skálázott bemeneti adatokkal dolgozunk. A ?-ek helyére írjuk be a hiányzó kódrészleteket."
      ],
      "metadata": {
        "id": "xoqR--S4ZjiP"
      },
      "id": "xoqR--S4ZjiP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e698ea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-11T05:37:24.680551Z",
          "iopub.status.busy": "2024-11-11T05:37:24.679637Z",
          "iopub.status.idle": "2024-11-11T05:37:24.831522Z",
          "shell.execute_reply": "2024-11-11T05:37:24.829856Z"
        },
        "papermill": {
          "duration": 0.164374,
          "end_time": "2024-11-11T05:37:24.834937",
          "exception": false,
          "start_time": "2024-11-11T05:37:24.670563",
          "status": "completed"
        },
        "tags": [],
        "id": "a3e698ea"
      },
      "outputs": [],
      "source": [
        "# K-Nearest Neighbors Model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_clf.fit(X_train_scaled, y_train)\n",
        "knn_pred = knn_clf.predict(X_test_scaled)\n",
        "\n",
        "# K-Nearest Neighbors értékelése\n",
        "print(\"K-Nearest Neighbors Metrics:\")\n",
        "print(f\"  Accuracy: {accuracy_score(y_test, knn_pred):.2f}\")\n",
        "print(f\"  Confusion Matrix:\\n {confusion_matrix(y_test, knn_pred)}\")\n",
        "print( confusion_matrix(y_test , knn_clf.predict(X_test_scaled)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix megjelenítése\n",
        "cm = confusion_matrix(y_test, knn_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=['No Rain', 'Rain'], yticklabels=['No Rain', 'Rain'])\n",
        "plt.title(\"KNN Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"Actual Class\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kIZkN-DCAxpz"
      },
      "id": "kIZkN-DCAxpz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. modell: Gradient Boosting\n",
        "\n",
        "Ebben az esetben is a skálázott bemeneti adatokkal dolgozunk. Az eredmény diagram megmutatja, hogy egy bemeneti változónak milyen a fontossága, vagyis, hogy arányosan mennyire járul hozzá a modell előrejelzéseihez.\n",
        "\n",
        "A ?-ek helyére írjuk be a hiányzó kódrészleteket."
      ],
      "metadata": {
        "id": "Rgi-ytkpZsha"
      },
      "id": "Rgi-ytkpZsha"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4922624c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-11T05:37:24.859037Z",
          "iopub.status.busy": "2024-11-11T05:37:24.858536Z",
          "iopub.status.idle": "2024-11-11T05:37:25.295829Z",
          "shell.execute_reply": "2024-11-11T05:37:25.294446Z"
        },
        "papermill": {
          "duration": 0.451328,
          "end_time": "2024-11-11T05:37:25.298650",
          "exception": false,
          "start_time": "2024-11-11T05:37:24.847322",
          "status": "completed"
        },
        "tags": [],
        "id": "4922624c"
      },
      "outputs": [],
      "source": [
        "# Gradient Boosting Model\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb_clf = GradientBoostingClassifier(random_state=42)\n",
        "gb_clf.fit(X_train_scaled, y_train)\n",
        "gb_pred = gb_clf.predict(X_test_scaled)\n",
        "\n",
        "# Evaluating Gradient Boosting\n",
        "print(\"Gradient Boosting Metrics:\")\n",
        "print(f\"  Accuracy: {accuracy_score(y_test, gb_pred):.2f}\")\n",
        "print(f\"  Confusion Matrix:\\n {confusion_matrix(y_test, gb_pred)}\")\n",
        "print(classification_report(y_test , gb_clf.predict(X_test_scaled)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Megjelenítjük a bemeneti jellemzők fontosságát (Feature Importance Plot)\n",
        "\n",
        "# feature importances megállapítása\n",
        "feature_importances = gb_clf.feature_importances_\n",
        "\n",
        "# Készítünk egy DataFrame-et az ábrázoláshoz\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# feature importances megjelenítése sávdiagrammal\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
        "plt.title('Gradient Boosting Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q700Z1_S_y1j"
      },
      "id": "Q700Z1_S_y1j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. modell: Decision Tree Classifier\n",
        "\n",
        "Ebben az esetben is a skálázott bemeneti adatokkal dolgozunk. A tanító fit() metódus alkalmazásakor a criterion = 'entropy' beállítással kiválasztjuk az alkalmazni kívánt döntési szabályt.\n",
        "\n",
        "A ?-ek helyére írjuk be a hiányzó kódrészleteket."
      ],
      "metadata": {
        "id": "9da6028a"
      },
      "id": "9da6028a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifier model\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "dt_clf = fit(criterion = 'entropy').fit(X_train_scaled, y_train)\n",
        "y_pred = dt_clf.predict(X_test_scaled)\n",
        "# Decision Tree Classifier értékelése\n",
        "print(\"Decision Tree Classifier:\")\n",
        "print(f\"  Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(f\"  Confusion Matrix:\\n {confusion_matrix(y_test, y_pred)}\")\n",
        "print(classification_report(y_test , dt_clf.predict(X_test_scaled)))\n"
      ],
      "metadata": {
        "id": "FHmmbcB7PhXv"
      },
      "id": "FHmmbcB7PhXv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A döntési fa megjelenítése\n",
        "plot_tree(dt_clf)"
      ],
      "metadata": {
        "id": "MMxVNL4t2oUB"
      },
      "id": "MMxVNL4t2oUB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 6021071,
          "sourceId": 9819966,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30786,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 24.682708,
      "end_time": "2024-11-11T05:37:42.512103",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-11-11T05:37:17.829395",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}